{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cae5586",
   "metadata": {},
   "source": [
    "# Telco Customer Churn Prediction\n",
    "\n",
    "This notebook reproduces the EDA, preprocessing, model training, and evaluation used to predict customer churn.\n",
    "\n",
    "Files in the project folder include trained models and preprocessing pipeline saved with `joblib`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = 'Telco-Customer-Churn-cleaned.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic preprocessing in this notebook cell\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'].replace(' ', np.nan))\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['MonthlyCharges'] * df['tenure']).fillna(df['MonthlyCharges'])\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop('customerID', axis=1)\n",
    "le = LabelEncoder()\n",
    "df['Churn'] = le.fit_transform(df['Churn'])\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "num_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "cat_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, numeric_features),('cat', cat_transformer, categorical_features)], remainder='drop', sparse_threshold=0)\n",
    "\n",
    "X_trans = preprocessor.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('Shapes:', X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('RandomForest accuracy:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "print('LogisticRegression accuracy:', accuracy_score(y_test, lr.predict(X_test)))\n",
    "\n",
    "print('\\nRandomForest classification report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importance (RandomForest)\n",
    "try:\n",
    "    ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "    cat_ohe_names = ohe.get_feature_names_out(categorical_features).tolist()\n",
    "    feature_names = numeric_features + cat_ohe_names\n",
    "except Exception:\n",
    "    feature_names = numeric_features\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "importances.head(20)\n",
    "\n",
    "# Save models and preprocessor\n",
    "joblib.dump(rf, 'rf_churn_model.joblib')\n",
    "joblib.dump(lr, 'lr_churn_model.joblib')\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "joblib.dump(le, 'label_encoder_churn.joblib')\n",
    "print('Saved models to current directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dc0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: load model and preprocessor, predict on first 5 rows\n",
    "rf2 = joblib.load('rf_churn_model.joblib')\n",
    "prep2 = joblib.load('preprocessor.joblib')\n",
    "le2 = joblib.load('label_encoder_churn.joblib')\n",
    "X_sample = df.drop('Churn', axis=1).iloc[:5]\n",
    "Xp = prep2.transform(X_sample)\n",
    "probs = rf2.predict_proba(Xp)[:,1]\n",
    "preds = rf2.predict(Xp)\n",
    "print('probs:', probs)\n",
    "print('preds (0=no,1=yes):', preds)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
